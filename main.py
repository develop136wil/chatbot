# main.py - Optimized Version
import os
import json
import uuid
import logging
import asyncio
import secrets  # [ì¶”ê°€] ë³´ì•ˆ í† í° ìƒì„±
from typing import List, Dict, Optional, Literal
from fastapi import FastAPI, Query, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, HTMLResponse
from pydantic import BaseModel
from starlette.middleware.sessions import SessionMiddleware
from dotenv import load_dotenv
from contextlib import asynccontextmanager
from apscheduler.schedulers.background import BackgroundScheduler
# [ìˆ˜ì •] run_indexingì€ ì‚¬ìš©í•˜ëŠ” ê³³ì—ì„œ import (startup crash ë°©ì§€)
# from index import run_indexing 
import pytz

# utilsì—ì„œ í•„ìš”í•œ ê²ƒë§Œ ë”± ê°€ì ¸ì˜µë‹ˆë‹¤.
from utils import (
    redis_client,
    redis_async_client, # [ì‹ ê·œ]
    MAIN_ANSWER_CACHE_KEY,
    extract_info_from_question,
    extract_info_from_question_async, # [ì‹ ê·œ]
    notion,   
    supabase, 
    # ì„ì‹œ: ë¹„ë™ê¸° í•¨ìˆ˜ë“¤ import ì˜¤ë¥˜ ë°©ì§€
    # supabase_async, search_supabase_async, check_semantic_cache_async
    # save_semantic_cache_async, get_gemini_embedding_async
    DATABASE_IDS                   
)

# ------------------------------------
# [ìµœì í™”] ì„¤ì • ìƒìˆ˜ ì •ì˜
# ------------------------------------
RATE_LIMIT_MAX_REQUESTS = 10
RATE_LIMIT_WINDOW_SECONDS = 60
LLM_TIMEOUT_SECONDS = 8
INITIAL_RESULT_DISPLAY_COUNT = 2
SUPABASE_KEEPALIVE_INTERVAL_HOURS = 12
CACHE_TTL_SECONDS = 3600
RESULTS_PER_PAGE = 2

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()
ADMIN_SECRET_KEY = os.getenv("ADMIN_SECRET_KEY", "your_strong_admin_password_here")

# --- ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ---
def scheduled_job():
    """ë§¤ì¼ ìë™ ì¸ë±ì‹± ì‘ì—…"""
    logger.info("â° [Scheduler] ìë™ ì¸ë±ì‹± ì‘ì—… ì‹œì‘...")
    try:
        from run_indexer import run_indexing # [ì´ë™] Lazy Import
        run_indexing()
        logger.info("â° [Scheduler] ìë™ ì¸ë±ì‹± ì‘ì—… ì™„ë£Œ!")
    except Exception as e:
        logger.error(f"âš ï¸ [Scheduler] ì¸ë±ì‹± ì‹¤íŒ¨: {e}")

def wake_up_supabase():
    """Supabase Free Tier ëŒ€ê¸° ìƒíƒœ ë°©ì§€"""
    try:
        response = supabase.table("site_pages").select("id").limit(1).execute()
        logger.info("â° [Keep-Alive] Supabase í•‘ ì„±ê³µ")
    except Exception as e:
        logger.warning(f"âš ï¸ [Keep-Alive] í•‘ ì „ì†¡ ì‹¤íŒ¨: {e}")

@asynccontextmanager
async def lifespan(app: FastAPI):
    """FastAPI ìˆ˜ëª… ì£¼ê¸° ê´€ë¦¬: ì‹œì‘/ì¢…ë£Œ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ì œì–´"""
    # Vercel í™˜ê²½ì—ì„œëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„í™œì„±í™”
    if os.getenv("VERCEL_ENV") or os.getenv("FORCE_SYNC_MODE"):
        logger.info("ğŸ”„ [Vercel] ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„í™œì„±í™” (ì„œë²„ë¦¬ìŠ¤ í™˜ê²½)")
        yield
        return
    
    # ë¡œì»¬ í™˜ê²½ì—ì„œë§Œ ìŠ¤ì¼€ì¤„ëŸ¬ í™œì„±í™”
    scheduler = BackgroundScheduler()
    korea_tz = pytz.timezone('Asia/Seoul')
    
    scheduler.add_job(scheduled_job, 'cron', hour=0, minute=0, timezone=korea_tz)
    scheduler.add_job(wake_up_supabase, 'interval', hours=SUPABASE_KEEPALIVE_INTERVAL_HOURS)
    
    scheduler.start()
    logger.info("âœ… [System] ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (ë§¤ì¼ 00:00 ì¸ë±ì‹±, %sì‹œê°„ë§ˆë‹¤ Keep-Alive)", SUPABASE_KEEPALIVE_INTERVAL_HOURS)
    
    yield
    
    # ì„œë²„ ì¢…ë£Œ ì‹œ
    scheduler.shutdown()
    logger.info("ğŸ›‘ [System] ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë£Œ")

# app ìƒì„± ì‹œ lifespan ì ìš©
app = FastAPI(lifespan=lifespan)

# --- CORS ì„¤ì • ---
# [ë³´ì•ˆ ê°•í™”] ì‹¤ì œ ë„ë©”ì¸ë§Œ ëª…ì‹œì  í—ˆìš©
origins = [
    "http://localhost:8080",
    "http://127.0.0.1:8080",
    "https://bluchany-dobong-welfare-bot.hf.space",
    "https://huggingface.co"
]
# í™˜ê²½ ë³€ìˆ˜ë¡œ ì¶”ê°€ ë„ë©”ì¸ ì„¤ì • ê°€ëŠ¥
if additional_origin := os.getenv("ADDITIONAL_CORS_ORIGIN"):
    origins.append(additional_origin)

app.add_middleware(
    CORSMiddleware, 
    allow_origins=origins, 
    allow_credentials=True, 
    allow_methods=["*"], 
    allow_headers=["*"]
)

# [ë³´ì•ˆ ê°•í™”] Session Secret Key í™˜ê²½ ë³€ìˆ˜í™”
SESSION_SECRET = os.getenv("SESSION_SECRET_KEY", secrets.token_hex(32))
app.add_middleware(SessionMiddleware, secret_key=SESSION_SECRET)

# --- ì •ì  íŒŒì¼ ì„œë¹™ ---
if os.path.exists("static"):
    app.mount("/static", StaticFiles(directory="static"), name="static")

# --- Redis í‚¤ ì´ë¦„ ---
JOB_QUEUE_KEY = "chatbot:job_queue"
JOB_RESULTS_KEY = "chatbot:job_results"

# --- ìš”ì²­ ëª¨ë¸ ---
class ChatRequest(BaseModel):
    question: str
    last_result_ids: List[str] = [] # [ìˆ˜ì •] List ì‚¬ìš© (ìƒë‹¨ import ë•ë¶„ì— ì—ëŸ¬ ì—†ìŒ)
    shown_count: int = 0
    chat_history: List[dict] = []   # [ìˆ˜ì •] List ì‚¬ìš©

# [main.py] ìƒë‹¨ í•¨ìˆ˜ ì •ì˜ ë¶€ë¶„ì— ì¶”ê°€

async def check_rate_limit(request: Request, limit: int = RATE_LIMIT_MAX_REQUESTS, window: int = RATE_LIMIT_WINDOW_SECONDS):
    """
    [ë¹„ë™ê¸°] ë„ë°° ë°©ì§€ (Rate Limiting) í•¨ìˆ˜
    """
    try:
        # 1. ì‚¬ìš©ì IP ê°€ì ¸ì˜¤ê¸°
        client_ip = request.headers.get("X-Forwarded-For")
        if client_ip:
            client_ip = client_ip.split(",")[0]
        else:
            client_ip = request.client.host
            
        # 2. Redis í‚¤ ìƒì„±
        key = f"rate_limit:{client_ip}"
        
        # [ìˆ˜ì •] ë¹„ë™ê¸° Redis ì‚¬ìš©
        if redis_async_client:
            current_count = await redis_async_client.get(key)
            
            if current_count and int(current_count) >= limit:
                logger.warning(f"ğŸš« [Rate Limit] ë„ë°° ê°ì§€! IP: {client_ip}")
                raise HTTPException(status_code=429, detail="ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. 1ë¶„ ë’¤ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ğŸ˜¥")
                
            # íŒŒì´í”„ë¼ì¸ë„ ë¹„ë™ê¸°ë¡œ
            pipe = redis_async_client.pipeline()
            await pipe.incr(key)
            if not current_count:
                await pipe.expire(key, window)
            await pipe.execute()
        
    except HTTPException:
        raise 
    except Exception as e:
        logger.error(f"âš ï¸ Rate Limit ì˜¤ë¥˜ (ì„œë²„ëŠ” ê³„ì† ì‘ë™): {e}")

# --- API ì—”ë“œí¬ì¸íŠ¸ ---

@app.get("/", response_class=HTMLResponse)
async def read_root():
    # [ìˆ˜ì •] íŒŒì¼ ì½ê¸° ë¬¸ì œë¥¼ ë°°ì œí•˜ê¸° ìœ„í•´ í•˜ë“œì½”ë”©ëœ HTML ë°˜í™˜
    return """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <title>ë„ë´‰êµ¬ ì˜ìœ ì•„ ë³µì§€í†¡</title>
        <style>
            body { font-family: sans-serif; display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0; background: #f0f2f5; }
            .loader { border: 4px solid #f3f3f3; border-top: 4px solid #3498db; border-radius: 50%; width: 40px; height: 40px; animation: spin 1s linear infinite; }
            @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }
        </style>
        <script>
            // 1ì´ˆ ë’¤ ì‹¤ì œ ë©”ì¸ í˜ì´ì§€ ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì‹œë„
            setTimeout(() => {
                // static íŒŒì¼ì´ ì˜ ì„œë¹™ë˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ redirection
                window.location.href = '/static/index.html'; 
            }, 1000);
        </script>
    </head>
    <body>
        <div style="text-align:center">
            <h1>ì±—ë´‡ ë¡œë”© ì¤‘...</h1>
            <div class="loader" style="margin: 20px auto;"></div>
            <p>ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.</p>
        </div>
    </body>
    </html>
    """

@app.get("/health")
def health_check():
    return {"status": "ok", "env": "vercel"}

@app.get("/debug")
def debug_check():
    """ì§„ë‹¨ìš© ì—”ë“œí¬ì¸íŠ¸: ê° ì—°ê²° ìƒíƒœë¥¼ ê°œë³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸"""
    results = {}
    
    # 1. Supabase ì—°ê²° í…ŒìŠ¤íŠ¸
    try:
        if supabase:
            resp = supabase.table("site_pages").select("id").limit(1).execute()
            results["supabase"] = f"âœ… OK (rows: {len(resp.data) if resp.data else 0})"
        else:
            results["supabase"] = "âŒ Client not initialized"
    except Exception as e:
        results["supabase"] = f"âŒ Error: {type(e).__name__}: {str(e)[:100]}"
    
    # 2. Gemini ì„ë² ë”© í…ŒìŠ¤íŠ¸
    try:
        from utils import get_gemini_embedding, KEY_POOL
        if KEY_POOL:
            embedding = get_gemini_embedding("í…ŒìŠ¤íŠ¸")
            if embedding:
                results["gemini_embed"] = f"âœ… OK (dim: {len(embedding)})"
            else:
                results["gemini_embed"] = "âŒ Returned None"
        else:
            results["gemini_embed"] = "âŒ No API keys"
    except Exception as e:
        results["gemini_embed"] = f"âŒ Error: {type(e).__name__}: {str(e)[:100]}"
    
    # 3. Redis ì—°ê²° í…ŒìŠ¤íŠ¸
    try:
        if redis_client:
            redis_client.ping()
            results["redis"] = "âœ… OK"
        else:
            results["redis"] = "âš ï¸ Not configured (fallback mode active)"
    except Exception as e:
        results["redis"] = f"âš ï¸ Error: {type(e).__name__}: {str(e)[:50]}"
    
    return results

@app.post("/admin/clear_cache")
def clear_all_caches(secret: str = Query(None)):
    if secret != ADMIN_SECRET_KEY: raise HTTPException(status_code=401, detail="Unauthorized")
    try:
        logger.warning("--- ğŸ”’ ê´€ë¦¬ì ìš”ì²­: Redis ìºì‹œ ì´ˆê¸°í™” ---")
        keys_to_delete = []
        for key_pattern in ["extract:*", "rank:*", "summary:*"]:
            keys_to_delete.extend(redis_client.keys(key_pattern))
        if keys_to_delete:
            redis_client.delete(*keys_to_delete)
        redis_client.delete(MAIN_ANSWER_CACHE_KEY) 
        redis_client.delete(JOB_RESULTS_KEY)
        return {"status": "Redis ìºì‹œ ì‚­ì œ ì™„ë£Œ"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì˜¤ë¥˜: {e}")



# [main.py] chat_with_bot í•¨ìˆ˜ ì „ì²´ êµì²´

@app.post("/chat")
async def chat_with_bot(chat_request: ChatRequest, request: Request):
    # 1. ë„ë°° ë°©ì§€ (ë¹„ë™ê¸° í˜¸ì¶œ)
    await check_rate_limit(request, limit=10, window=60) 

    session = request.session
    question = chat_request.question.strip()
    chat_history = chat_request.chat_history
    logger.info(f"ë°›ì€ ì§ˆë¬¸: {question}")

    if not notion: raise HTTPException(status_code=503, detail="Notion API Key ì„¤ì • ì˜¤ë¥˜")

    normalized_input = question.strip().lower()
    input_no_spaces = normalized_input.replace(" ", "")

    # [ìˆ˜ì •] Redis ìƒíƒœ í™•ì¸ (Vercel í™˜ê²½ì—ì„œëŠ” ê°•ì œë¡œ ë™ê¸° ëª¨ë“œ)
    # Vercel í™˜ê²½ ë³€ìˆ˜ê°€ ìˆê±°ë‚˜ Redis í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìœ¼ë©´ ë™ê¸° ëª¨ë“œë¡œ ê°•ì œ ì „í™˜
    force_sync_mode = os.getenv("VERCEL_ENV") == "production" or os.getenv("FORCE_SYNC_MODE") == "true"
    is_redis_down = force_sync_mode or (redis_async_client is None)
    
    if force_sync_mode:
        logger.info("ğŸ”„ Vercel í™˜ê²½ ê°ì§€: ë™ê¸° ëª¨ë“œë¡œ ê°•ì œ ì „í™˜")

    # 2. AI ì˜ë„ ë¶„ì„ (ë¹„ë™ê¸° í˜¸ì¶œ)
    try:
        extracted_info = await extract_info_from_question_async(question, chat_history)
        if isinstance(extracted_info, dict) and "error" in extracted_info:
             raise HTTPException(status_code=500, detail=extracted_info["error"])
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì§ˆë¬¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")


    # 3. 'ë” ë³´ê¸°' ê°ì§€
    show_more_keywords = ["ë”", "ë‹¤ìŒ", "ê³„ì†", "more", "next", "ë‹¤ë¥¸", "ë˜"]
    is_keyword_match = any(k in input_no_spaces for k in show_more_keywords)
    is_ai_match = extracted_info.get("intent") == "show_more"
    is_show_more = (is_keyword_match or is_ai_match)
    
    # 'ë” ë³´ê¸°' ì‹¤í–‰ (Redisê°€ ì£½ì–´ë„ SupabaseëŠ” ì‚´ì•„ìˆìœ¼ë¯€ë¡œ ì‘ë™ ê°€ëŠ¥)
    if is_show_more and chat_request.last_result_ids:
        logger.info("[API] 'ë” ë³´ê¸°' ìš”ì²­ ì²˜ë¦¬")
        try:
            start = chat_request.shown_count
            end = start + 2
            target_ids = chat_request.last_result_ids[start:end]
            
            if not target_ids:
                return {"status": "complete", "answer": "ë” ì´ìƒ í‘œì‹œí•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "last_result_ids": chat_request.last_result_ids, "total_found": len(chat_request.last_result_ids)}

            from utils import get_supabase_pages_by_ids_async, format_search_results
            
            # ë¹„ë™ê¸° ë²„ì „ìœ¼ë¡œ Supabase ì¡°íšŒ
            next_pages = await get_supabase_pages_by_ids_async(target_ids)
            formatted_body = format_search_results(next_pages)
            
            remaining = len(chat_request.last_result_ids) - end

            header = f"<p>ğŸ” <b>ì¶”ê°€ ì •ë³´ ({start+1}~{start+len(next_pages)}ë²ˆì§¸)</b></p>"
            answer_text = f"{header}<hr>{formatted_body}"
            
            if remaining > 0:
                answer_text += f"<hr><p>ğŸ” <b>ì•„ì§ ê²°ê³¼ê°€ ë” ë‚¨ì•„ìˆìŠµë‹ˆë‹¤.</b> 'ë” ë³´ì—¬ì¤˜' ë˜ëŠ” 'ë‹¤ìŒ'ì„ ì…ë ¥í•´ ë³´ì„¸ìš”.</p>"
            else:
                answer_text += "<hr><p>âœ… <b>ëª¨ë“  ê²°ê³¼ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.</b></p>"

            return {
                "status": "complete", 
                "answer": answer_text, 
                "last_result_ids": chat_request.last_result_ids, 
                "total_found": len(chat_request.last_result_ids),
                "shown_count": end 
            }
        except Exception as e:
            logger.error(f"âŒ ë” ë³´ê¸° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    # 4. ì˜ë„ë³„ ë¶„ê¸° (Small talk ë“±)
    if extracted_info.get("intent") == "safety_block":
        return {"status": "complete", "answer": "ë¹„ì†ì–´ëŠ” ì‚¼ê°€ì£¼ì„¸ìš”. ğŸ˜¥ ë³µì§€ ì •ë³´ì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.", "last_result_ids": [], "total_found": 0}
    
    if extracted_info.get("intent") == "exit":
        return {"status": "complete", "answer": "ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ì–¸ì œë“  ë‹¤ì‹œ ì°¾ì•„ì£¼ì„¸ìš”! ğŸ˜Š", "last_result_ids": [], "total_found": 0}
    
    if extracted_info.get("intent") == "reset":
        return {"status": "complete", "answer": "ëŒ€í™”ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? ğŸ¤–", "last_result_ids": [], "total_found": 0}

    if extracted_info.get("intent") == "out_of_scope":
        return {"status": "complete", "answer": "ì €ëŠ” ì˜ìœ ì•„ ë³µì§€ ì •ë³´ë§Œ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆì–´ìš”. ğŸ˜…", "last_result_ids": [], "total_found": 0}

    if extracted_info.get("intent") == "small_talk":
        answer = "ì•ˆë…•í•˜ì„¸ìš”! ë„ë´‰êµ¬ ì˜ìœ ì•„ ë³µì§€ ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
        if "ê³ ë§ˆ" in normalized_input: answer = "ë„ì›€ì´ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤! ğŸ˜Š"
        return {"status": "complete", "answer": answer, "last_result_ids": [], "total_found": 0}

    if extracted_info.get("intent") == "clarify_category":
        age_info = extracted_info.get("age")
        age_text = f"{age_info}ê°œì›” ì•„ê¸°" if age_info else "ìë…€"
        return {"status": "clarify", "answer": f"{age_text}ë¥¼ ìœ„í•œ ì–´ë–¤ ì •ë³´ê°€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?", "options": list(DATABASE_IDS.keys()), "last_result_ids": [], "total_found": 0}

    # 5. ìºì‹œ í™•ì¸ (Redis Async)
    if not is_redis_down:
        try:
            cached_data = await redis_async_client.hget(MAIN_ANSWER_CACHE_KEY, question)
            if cached_data:
                logger.info(f"âœ… [API] Cache Hit!")
                session.clear(); session["last_question"] = question
                return json.loads(cached_data.decode('utf-8'))
        except Exception: pass

    # 6. ì‘ì—… ì²˜ë¦¬ (ë¹„ìƒ ëª¨ë“œ í¬í•¨)
    logger.info("[API] Job ìƒì„± ë° ì²˜ë¦¬ ì‹œì‘.")
    
    job_id = str(uuid.uuid4())
    ai_category = extracted_info.get("category") if isinstance(extracted_info, dict) else None
    
    job_data = {
        "job_id": job_id, 
        "question": question, 
        "chat_history": chat_history,
        "ai_category": ai_category
    }

    # [í•µì‹¬ ìˆ˜ì •] Redisê°€ ì£½ì—ˆìœ¼ë©´ -> ë™ê¸° ëª¨ë“œ(ì§ì ‘ ì‹¤í–‰)
    if is_redis_down:
        logger.warning(f"âš ï¸ [Fallback] Redis ì—°ê²° ë¶ˆê°€. Workerë¥¼ ìš°íšŒí•˜ì—¬ ì§ì ‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        try:
            from worker import process_job 
            
            # ë¹„ë™ê¸° ì‹¤í–‰ (ThreadPoolExecutorì— ìœ„ì„í•˜ì—¬ ë¸”ë¡œí‚¹ ë°©ì§€)
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, process_job, job_data)
            
            # resultëŠ” (final_answer, all_page_ids, total_found) íŠœí”Œ
            if isinstance(result, tuple) and len(result) == 3:
                final_answer, page_ids, total_found = result
                return {
                    "status": "complete", 
                    "answer": final_answer,
                    "last_result_ids": page_ids,
                    "total_found": total_found
                }
            else:
                # ì˜ˆê¸°ì¹˜ ì•Šì€ ê²°ê³¼ í˜•ì‹
                logger.error(f"âŒ Fallback ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜: {type(result)} - {result}")
                return {"error": "ì²˜ë¦¬ ê²°ê³¼ í˜•ì‹ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}
            
        except Exception as e:
            logger.error(f"âŒ Fallback ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {"error": "ì¼ì‹œì ì¸ ì„œë¹„ìŠ¤ ì¥ì• ì…ë‹ˆë‹¤."}

    # Redisê°€ ì‚´ì•„ìˆìœ¼ë©´ -> íì— ë„£ê¸° (Async)
    try: 
        await redis_async_client.rpush(JOB_QUEUE_KEY, json.dumps(job_data, ensure_ascii=False).encode('utf-8'))
        session.clear(); session["last_question"] = question
        return {"message": "ìš”ì²­ ì ‘ìˆ˜ ì™„ë£Œ.", "job_id": job_id}
    except Exception as e: 
        logger.error(f"âŒ Redis Push ì‹¤íŒ¨: {e}")
        return {"error": "ëŒ€ê¸°ì—´ ë“±ë¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."}

@app.get("/get_result/{job_id}")
def get_job_result(job_id: str):
    try:
        result_bytes = redis_client.hget(JOB_RESULTS_KEY, job_id)
        if result_bytes:
            return json.loads(result_bytes.decode('utf-8'))
        else:
            return {"status": "pending"}
    except Exception as e: raise HTTPException(status_code=500, detail=f"ì˜¤ë¥˜: {e}")

# --- í”¼ë“œë°± DB ---
FEEDBACK_DB_ID = os.getenv("NOTION_FEEDBACK_DB_ID", "2c18ade5021080448ab8d304b4777fe5")

# [ìˆ˜ì •] FeedbackRequest ëª¨ë¸ í™•ì¥
class FeedbackRequest(BaseModel):
    job_id: str
    question: str
    answer: str
    feedback: Literal["ğŸ‘", "ğŸ‘"]
    reason: Optional[str] = ""     # [ì‹ ê·œ] í†µê³„ìš© ì‚¬ìœ  (ì˜ˆ: ì •ë³´ë¶€ì¡±)
    comment: Optional[str] = ""    # ìƒì„¸ ì˜ê²¬
    chat_history: Optional[str] = "" # [ì‹ ê·œ] ì´ì „ ëŒ€í™” ë‚´ì—­ (í…ìŠ¤íŠ¸ë¡œ ì €ì¥)

@app.post("/feedback")
async def handle_feedback(feedback_data: FeedbackRequest):
    if not notion: raise HTTPException(status_code=503, detail="Notion API ì˜¤ë¥˜")
    
    try:
        notion.pages.create(
            parent={"database_id": "2c18ade5021080448ab8d304b4777fe5"}, # ë”°ì˜´í‘œ í™•ì¸!
            properties={
                "ì§ˆë¬¸": {"title": [{"text": {"content": feedback_data.question[:2000]}}]},
                "ë‹µë³€": {"rich_text": [{"text": {"content": feedback_data.answer[:2000]}}]},
                "í‰ê°€": {"select": {"name": feedback_data.feedback}},
                
                # [ì‹ ê·œ] ì‚¬ìœ  (ì„ íƒ ì†ì„±ìœ¼ë¡œ ì €ì¥ -> í†µê³„ ê°€ëŠ¥)
                "ì‚¬ìœ ": {"select": {"name": feedback_data.reason}} if feedback_data.reason else None,
                
                # [ì‹ ê·œ] ëŒ€í™”ë‚´ì—­ (ë¬¸ë§¥ íŒŒì•…ìš©)
                "ëŒ€í™”ë‚´ì—­": {"rich_text": [{"text": {"content": feedback_data.chat_history[:2000]}}]},
                
                "ìƒì„¸ì˜ê²¬": {"rich_text": [{"text": {"content": feedback_data.comment[:2000] if feedback_data.comment else ""}}]},
                "ì‘ì—…ID": {"rich_text": [{"text": {"content": feedback_data.job_id}}]}
            }
        )
        return {"status": "success"}
    except Exception as e:
        logger.error(f"âŒ í”¼ë“œë°± ì €ì¥ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì €ì¥ ì‹¤íŒ¨")